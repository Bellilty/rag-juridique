# ğŸ¤– Assistant Juridique RAG Local

Un projet pÃ©dagogique pour apprendre le **RAG (Retrieval-Augmented Generation)** et **FastAPI** en crÃ©ant un assistant juridique local qui rÃ©pond Ã  des questions sur des documents lÃ©gaux.

## ğŸ“š Table des matiÃ¨res

- [Concept](#-concept)
- [Architecture](#-architecture)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du projet](#-structure-du-projet)
- [Explications dÃ©taillÃ©es](#-explications-dÃ©taillÃ©es)
- [CoÃ»ts](#-coÃ»ts)
- [AmÃ©liorations possibles](#-amÃ©liorations-possibles)

---

## ğŸ¯ Concept

### Qu'est-ce que le RAG ?

**RAG = Retrieval-Augmented Generation**

C'est une technique qui combine :

1. **Retrieval (RÃ©cupÃ©ration)** : Chercher des informations pertinentes dans une base de documents
2. **Augmented (Enrichissement)** : Ajouter ces informations au contexte du LLM
3. **Generation (GÃ©nÃ©ration)** : Le LLM gÃ©nÃ¨re une rÃ©ponse basÃ©e sur ce contexte

### Pourquoi le RAG ?

Sans RAG :

- âŒ Le LLM rÃ©pond avec ses connaissances gÃ©nÃ©rales (peut Ãªtre obsolÃ¨te)
- âŒ Risque d'hallucinations (inventer des informations)
- âŒ Pas de sources vÃ©rifiables

Avec RAG :

- âœ… Le LLM rÃ©pond avec **VOS** documents
- âœ… RÃ©ponses factuelles basÃ©es sur des sources rÃ©elles
- âœ… Citations des sources
- âœ… ContrÃ´le total sur les donnÃ©es

### Ce que fait ce projet

```
ğŸ“„ PDFs juridiques (GDPR, Constitution, etc.)
    â†“
ğŸ”ª DÃ©coupage en chunks (morceaux de texte)
    â†“
ğŸ”¢ CrÃ©ation d'embeddings (vecteurs)
    â†“
ğŸ“Š Indexation avec FAISS (recherche rapide)
    â†“
â“ Question utilisateur
    â†“
ğŸ” Recherche des passages pertinents
    â†“
ğŸ¤– GÃ©nÃ©ration de la rÃ©ponse avec OpenAI
    â†“
ğŸ’¬ RÃ©ponse + citations
```

---

## ğŸ—ï¸ Architecture

### Modules principaux

| Module           | RÃ´le                                   | Technologies      |
| ---------------- | -------------------------------------- | ----------------- |
| `extract_pdf.py` | Extraction et chunking des PDFs        | PyMuPDF           |
| `embeddings.py`  | CrÃ©ation des embeddings et index FAISS | OpenAI API, FAISS |
| `retrieval.py`   | Recherche et gÃ©nÃ©ration RAG            | OpenAI API, FAISS |
| `api.py`         | API REST                               | FastAPI           |

### Flux de donnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/pdfs/ â”‚  Dossier contenant les PDFs
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ extract_pdf.py
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chunks    â”‚  Texte dÃ©coupÃ© en morceaux
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ embeddings.py + OpenAI
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embeddings â”‚  Vecteurs numÃ©riques
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ FAISS
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ index/      â”‚  Index FAISS + chunks.pkl
â”‚ legal.faiss â”‚
â”‚ chunks.pkl  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ api.py
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI    â”‚  http://localhost:8000
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Backend

- **Python 3.10+** : Langage principal
- **FastAPI** : Framework web moderne et rapide
- **Uvicorn** : Serveur ASGI pour FastAPI

### RAG & IA

- **OpenAI API** :
  - `text-embedding-3-small` : CrÃ©ation d'embeddings (~$0.02/1M tokens)
  - `gpt-4o-mini` : GÃ©nÃ©ration de rÃ©ponses (~$0.15/1M tokens input)
- **FAISS** : Recherche vectorielle ultra-rapide (Facebook AI)
- **PyMuPDF (fitz)** : Extraction de texte depuis PDFs

### Utilitaires

- **NumPy** : Calculs sur les vecteurs
- **Pydantic** : Validation des donnÃ©es
- **python-dotenv** : Gestion des variables d'environnement

---

## ğŸ“¦ Installation

### 1. PrÃ©requis

- Python 3.10 ou supÃ©rieur
- pip
- Une clÃ© API OpenAI ([crÃ©er une clÃ©](https://platform.openai.com/api-keys))

### 2. Cloner le projet

```bash
cd /chemin/vers/rag-juridique
```

### 3. CrÃ©er l'environnement virtuel

```bash
# CrÃ©ation du venv
python3 -m venv venv

# Activation
source venv/bin/activate  # Linux/Mac
# OU
.\venv\Scripts\activate  # Windows
```

### 4. Installation automatique (recommandÃ©)

```bash
python setup.py
```

Ce script va :

- Installer les dÃ©pendances
- Configurer la clÃ© API
- Proposer de tÃ©lÃ©charger des donnÃ©es de dÃ©mo
- CrÃ©er l'index FAISS

### 5. Installation manuelle

```bash
# Installer les dÃ©pendances
pip install -r requirements.txt

# CrÃ©er le fichier .env


# Ajouter des PDFs dans data/pdfs/
# (par exemple : GDPR, Constitution US, etc.)

# CrÃ©er l'index FAISS
python -m src.embeddings
```

---

## ğŸš€ Utilisation

### 1. Ajouter des documents

Place tes PDFs juridiques dans le dossier `data/pdfs/`.

**Suggestions de sources gratuites :**

- ğŸ‡ªğŸ‡º [GDPR](https://gdpr-info.eu/) - RÃ¨glement europÃ©en sur la protection des donnÃ©es
- ğŸ‡ºğŸ‡¸ [U.S. Constitution](https://www.archives.gov/founding-docs) - Constitution amÃ©ricaine
- ğŸ‡«ğŸ‡· [Code civil franÃ§ais](https://www.legifrance.gouv.fr/codes/id/LEGITEXT000006070721/) - LÃ©gifrance

### 2. CrÃ©er l'index FAISS

```bash
python -m src.embeddings
```

Ce script va :

1. Extraire le texte des PDFs
2. DÃ©couper en chunks
3. CrÃ©er les embeddings via OpenAI
4. CrÃ©er l'index FAISS
5. Sauvegarder dans `index/`

**DurÃ©e** : ~1-2 minutes pour 2-3 PDFs de taille moyenne

### 3. Lancer l'API

```bash
uvicorn src.api:app --reload
```

L'API sera accessible sur : `http://localhost:8000`

### 4. Tester l'API

#### Via le navigateur

```
http://localhost:8000/ask?query=What%20is%20GDPR
```

#### Via la documentation Swagger

Ouvre `http://localhost:8000/docs` pour une interface interactive complÃ¨te !

#### Via curl

```bash
curl "http://localhost:8000/ask?query=What%20is%20GDPR&k=3"
```

#### Via Python

```python
import requests

response = requests.get(
    "http://localhost:8000/ask",
    params={
        "query": "What are the main principles of GDPR?",
        "k": 3,
        "model": "gpt-4o-mini"
    }
)

result = response.json()
print(result['answer'])
```

### 5. Exemples de questions

```
ğŸ‡«ğŸ‡· FranÃ§ais :
- "Quel est l'article sur la responsabilitÃ© civile ?"
- "Que dit la loi sur la protection des donnÃ©es ?"

ğŸ‡ºğŸ‡¸ Anglais :
- "What is Article 5 of GDPR about?"
- "What are data subject rights under GDPR?"
- "Who is the data controller?"
```

---

## ğŸ“‚ Structure du projet

```
rag-juridique/
â”‚
â”œâ”€â”€ venv/                      # Environnement virtuel Python
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/                  # ğŸ“„ Place tes PDFs ici
â”‚       â”œâ”€â”€ GDPR.pdf
â”‚       â””â”€â”€ US_Constitution.pdf
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract_pdf.py         # ğŸ”ª Extraction et chunking
â”‚   â”œâ”€â”€ embeddings.py          # ğŸ”¢ Embeddings + FAISS
â”‚   â”œâ”€â”€ retrieval.py           # ğŸ” Recherche et gÃ©nÃ©ration RAG
â”‚   â””â”€â”€ api.py                 # ğŸŒ API FastAPI
â”‚
â”œâ”€â”€ index/
â”‚   â”œâ”€â”€ legal.faiss            # ğŸ“Š Index FAISS (gÃ©nÃ©rÃ©)
â”‚   â””â”€â”€ chunks.pkl             # ğŸ’¾ Chunks sauvegardÃ©s (gÃ©nÃ©rÃ©)
â”‚
â”œâ”€â”€ requirements.txt           # ğŸ“¦ DÃ©pendances Python
â”œâ”€â”€ setup.py                   # ğŸ› ï¸ Script d'installation
â”œâ”€â”€ .env                       # ğŸ”‘ ClÃ© API (Ã  crÃ©er)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                  # ğŸ“– Ce fichier
```

---

## ğŸ§  Explications dÃ©taillÃ©es

### 1. Extraction et Chunking (`extract_pdf.py`)

#### Pourquoi dÃ©couper en chunks ?

- Les LLMs ont une **limite de tokens** dans leur contexte
- Les petits morceaux permettent une **recherche plus prÃ©cise**
- L'**overlap** (chevauchement) Ã©vite de couper des phrases importantes

#### ParamÃ¨tres du chunking

```python
chunk_size = 1000    # Nombre de mots par chunk
overlap = 200        # Mots qui se chevauchent entre chunks
```

**Exemple :**

```
Texte original : "Article 1. [...] Article 2. [...] Article 3. [...]"

Chunk 1 : "Article 1. [...] Article 2. [premiers mots]"
Chunk 2 : "[derniers mots Article 1] Article 2. [...] Article 3. [...]"
         â†‘ overlap (Ã©vite de perdre du contexte)
```

### 2. Embeddings (`embeddings.py`)

#### Qu'est-ce qu'un embedding ?

Un **embedding** est une reprÃ©sentation vectorielle d'un texte.

```python
texte = "GDPR protects personal data"
embedding = [0.123, -0.456, 0.789, ...]  # 1536 dimensions
```

**PropriÃ©tÃ© magique** : Les textes similaires ont des vecteurs proches !

```python
"data protection" â†’ [0.1, 0.2, 0.3, ...]
"privacy law"     â†’ [0.12, 0.19, 0.31, ...]  # Proche !
"pizza recipe"    â†’ [0.9, -0.5, 0.1, ...]    # Loin !
```

#### Pourquoi OpenAI `text-embedding-3-small` ?

- âœ… Moins cher (~$0.02/1M tokens)
- âœ… Performance excellente
- âœ… 1536 dimensions (bon Ã©quilibre)
- âœ… Multilingue

### 3. FAISS

#### Qu'est-ce que FAISS ?

**FAISS** (Facebook AI Similarity Search) est une bibliothÃ¨que pour rechercher des vecteurs similaires **ultra-rapidement**.

**Sans FAISS** :

```python
# Comparer la question avec TOUS les chunks (lent!)
for chunk in chunks:
    distance = calculate_distance(query_vector, chunk_vector)
```

**Avec FAISS** :

```python
# Index optimisÃ©, recherche instantanÃ©e mÃªme avec 1M de vecteurs
index.search(query_vector, k=3)  # Trouve les 3 plus proches en millisecondes
```

#### Types d'index FAISS

| Index         | PrÃ©cision | Vitesse     | Usage                     |
| ------------- | --------- | ----------- | ------------------------- |
| `IndexFlatL2` | 100%      | Moyen       | < 1M vecteurs (notre cas) |
| `IndexIVF`    | ~95%      | Rapide      | > 1M vecteurs             |
| `IndexHNSW`   | ~99%      | TrÃ¨s rapide | Production                |

**Pour ce projet** : `IndexFlatL2` suffit largement !

### 4. Retrieval-Augmented Generation (`retrieval.py`)

#### Le processus RAG en dÃ©tail

```python
# 1. L'utilisateur pose une question
query = "What is GDPR?"

# 2. On vectorise la question
query_vector = create_embedding(query)
# â†’ [0.1, 0.2, 0.3, ...]

# 3. FAISS trouve les chunks les plus proches
distances, indices = index.search(query_vector, k=3)
# â†’ Retourne les 3 chunks les plus pertinents

# 4. On construit le contexte
context = "\n\n".join([chunks[i] for i in indices])

# 5. On construit le prompt pour le LLM
prompt = f"""
You are a legal assistant.
Answer based ONLY on this context:

{context}

Question: {query}
"""

# 6. Le LLM gÃ©nÃ¨re la rÃ©ponse
answer = openai.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}]
)
```

#### Pourquoi `gpt-4o-mini` ?

| ModÃ¨le        | Prix (input) | Prix (output) | QualitÃ©            |
| ------------- | ------------ | ------------- | ------------------ |
| gpt-4o-mini   | $0.15/1M     | $0.60/1M      | â­â­â­â­ Excellent |
| gpt-3.5-turbo | $0.50/1M     | $1.50/1M      | â­â­â­ Bon         |
| gpt-4         | $30/1M       | $60/1M        | â­â­â­â­â­ Parfait |

**Verdict** : `gpt-4o-mini` offre le **meilleur rapport qualitÃ©/prix** !

### 5. API FastAPI (`api.py`)

#### Pourquoi FastAPI ?

- âœ… **Rapide** : Performance comparable Ã  NodeJS
- âœ… **Documentation auto** : Swagger UI intÃ©grÃ©
- âœ… **Validation** : Pydantic vÃ©rifie les donnÃ©es automatiquement
- âœ… **Async** : Support natif des opÃ©rations asynchrones
- âœ… **Moderne** : Type hints Python 3.6+

#### Endpoints disponibles

| Endpoint    | MÃ©thode | Description                        |
| ----------- | ------- | ---------------------------------- |
| `/`         | GET     | Infos sur l'API                    |
| `/health`   | GET     | VÃ©rifie l'Ã©tat de l'API            |
| `/stats`    | GET     | Statistiques sur l'index           |
| `/ask`      | GET     | Pose une question (paramÃ¨tres URL) |
| `/ask_post` | POST    | Pose une question (JSON body)      |
| `/docs`     | GET     | Documentation Swagger              |
| `/redoc`    | GET     | Documentation ReDoc                |

---

## ğŸ’° CoÃ»ts

### Estimation des coÃ»ts OpenAI

Pour **100 questions** sur **3 PDFs** (~50 pages chacun) :

| Ã‰tape                | OpÃ©ration           | Tokens | CoÃ»t unitaire                  | CoÃ»t total |
| -------------------- | ------------------- | ------ | ------------------------------ | ---------- |
| **Setup** (une fois) | Embeddings crÃ©ation | ~50K   | $0.02/1M                       | **$0.001** |
| **Par question**     | Embedding query     | ~20    | $0.02/1M                       | $0.0000004 |
| **Par question**     | LLM gÃ©nÃ©ration      | ~1000  | $0.15/1M (in) + $0.60/1M (out) | $0.0005    |

**Total pour 100 questions** : ~**$0.05** ğŸ’°

### Comparaison avec d'autres solutions

| Solution               | CoÃ»t pour 100 questions | Limitations                    |
| ---------------------- | ----------------------- | ------------------------------ |
| **Ce projet (OpenAI)** | $0.05                   | Aucune                         |
| ChatGPT Plus           | $20/mois                | Pas de donnÃ©es custom          |
| Claude Pro             | $20/mois                | Pas de donnÃ©es custom          |
| Ollama (local)         | $0 (gratuit)            | NÃ©cessite GPU, qualitÃ© moindre |

---

## ğŸš€ AmÃ©liorations possibles

### 1. Support de plus de formats

```python
# Ajouter support pour .txt, .docx, .html
from docx import Document
from bs4 import BeautifulSoup
```

### 2. Interface utilisateur

```bash
pip install streamlit

# CrÃ©er une UI simple
streamlit run ui.py
```

### 3. Mode 100% offline avec Ollama

```python
# Remplacer OpenAI par Ollama (LLM local)
from langchain.llms import Ollama

llm = Ollama(model="mistral")
```

### 4. MÃ©tadonnÃ©es enrichies

```python
chunk = {
    "text": "...",
    "source": "GDPR.pdf",
    "article": "Article 5",    # â† Nouveau !
    "page": 12,                # â† Nouveau !
    "section": "Principles"    # â† Nouveau !
}
```

### 5. Index multi-lois avec filtres

```python
# Chercher uniquement dans le GDPR
results = retriever.search(
    query="data protection",
    filters={"source": "GDPR.pdf"}
)
```

### 6. Cache des questions frÃ©quentes

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def ask_cached(query: str):
    return retriever.ask(query)
```

### 7. SystÃ¨me de feedback

```python
@app.post("/feedback")
def submit_feedback(query: str, helpful: bool):
    # Stocker pour amÃ©liorer le systÃ¨me
    save_feedback(query, helpful)
```

---

## ğŸ“ Concepts clÃ©s appris

En complÃ©tant ce projet, tu auras appris :

### RAG

- âœ… Comment fonctionne la recherche sÃ©mantique
- âœ… Le principe des embeddings vectoriels
- âœ… L'utilisation de FAISS pour la recherche rapide
- âœ… Comment enrichir un LLM avec des donnÃ©es externes

### FastAPI

- âœ… CrÃ©er une API REST moderne
- âœ… Validation automatique avec Pydantic
- âœ… Documentation auto avec Swagger
- âœ… Gestion des erreurs et des Ã©tats

### Bonnes pratiques

- âœ… Environnements virtuels Python
- âœ… Gestion des secrets (.env)
- âœ… Structure modulaire d'un projet
- âœ… Documentation complÃ¨te

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : "ClÃ© API non trouvÃ©e"

```bash
# VÃ©rifie que le fichier .env existe
ls -la .env

# VÃ©rifie le contenu
cat .env

# Doit contenir :
OPENAI_API_KEY=sk-...
```

### ProblÃ¨me : "Index non trouvÃ©"

```bash
# CrÃ©e l'index
python -m src.embeddings

# VÃ©rifie qu'il existe
ls -la index/
```

### ProblÃ¨me : "Module not found"

```bash
# VÃ©rifie que le venv est activÃ©
which python  # Doit pointer vers venv/bin/python

# RÃ©installe les dÃ©pendances
pip install -r requirements.txt
```

### ProblÃ¨me : "FAISS installation failed"

```bash
# Sur Mac avec Apple Silicon
pip install faiss-cpu --no-cache

# Sur Windows
pip install faiss-cpu==1.7.4
```

---

## ğŸ“š Ressources supplÃ©mentaires

### Documentation officielle

- [OpenAI API](https://platform.openai.com/docs)
- [FastAPI](https://fastapi.tiangolo.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [LangChain](https://python.langchain.com/) (framework RAG plus avancÃ©)

### Tutoriels

- [RAG from Scratch](https://www.youtube.com/watch?v=sVcwVQRHIc8) (vidÃ©o)
- [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/)
- [Vector Databases Explained](https://www.pinecone.io/learn/vector-database/)

### Alternatives Ã  explorer

- **Pinecone** : Base de donnÃ©es vectorielle cloud
- **Weaviate** : Base de donnÃ©es vectorielle open source
- **ChromaDB** : Alternative simple Ã  FAISS
- **LlamaIndex** : Framework RAG simplifiÃ©

---

## ğŸ¤ Contribution

Ce projet est Ã  but pÃ©dagogique. N'hÃ©site pas Ã  :

- ExpÃ©rimenter avec diffÃ©rents paramÃ¨tres
- Ajouter de nouvelles fonctionnalitÃ©s
- Tester d'autres modÃ¨les (Anthropic Claude, etc.)
- Comparer les performances

---

## ğŸ“ Licence

Ce projet est libre d'utilisation Ã  des fins Ã©ducatives.

**Note** : Respecte les conditions d'utilisation d'OpenAI et les licences des documents juridiques que tu utilises.

---

## ğŸ‰ Bravo !

Tu as maintenant un assistant juridique RAG fonctionnel !

**Prochaines Ã©tapes suggÃ©rÃ©es :**

1. Teste avec diffÃ©rents types de documents
2. ExpÃ©rimente avec les paramÃ¨tres (chunk_size, k, temperature)
3. Ajoute une interface utilisateur avec Streamlit
4. Essaye d'autres modÃ¨les (Claude, Llama, Mistral)
5. Explore les bases de donnÃ©es vectorielles (Pinecone, Weaviate)

**Questions ?** Documente tes expÃ©riences et continue Ã  apprendre ! ğŸš€
